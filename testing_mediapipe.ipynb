{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from mediapipe.python.solutions.pose import PoseLandmark\n",
    "from mediapipe.python.solutions.drawing_utils import DrawingSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Access using Using MediaPipe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define mediapipe holistic and drawing utils\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect using mediapipe model\n",
    "def media_pipe_detection(image, model):\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB) \n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv.cvtColor(image, cv.COLOR_RGB2BGR) \n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw landmarks without style\n",
    "def draw_land_marks(image, results):\n",
    "    # mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION)\n",
    "    \n",
    "    # mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "\n",
    "    custom_pose_connections = list(mp_pose.POSE_CONNECTIONS)\n",
    "    \n",
    "    excluded_landmarks = [\n",
    "        PoseLandmark.NOSE,\n",
    "        PoseLandmark.LEFT_EYE_INNER,\n",
    "        PoseLandmark.LEFT_EYE,\n",
    "        PoseLandmark.LEFT_EYE_OUTER,\n",
    "        PoseLandmark.RIGHT_EYE_INNER,\n",
    "        PoseLandmark.RIGHT_EYE,\n",
    "        PoseLandmark.RIGHT_EYE_OUTER,\n",
    "        PoseLandmark.LEFT_EAR,\n",
    "        PoseLandmark.RIGHT_EAR,\n",
    "        PoseLandmark.MOUTH_LEFT,\n",
    "        PoseLandmark.MOUTH_RIGHT,\n",
    "        PoseLandmark.LEFT_HIP,\n",
    "        PoseLandmark.RIGHT_HIP,\n",
    "        PoseLandmark.LEFT_KNEE,\n",
    "        PoseLandmark.RIGHT_KNEE,\n",
    "        PoseLandmark.LEFT_ANKLE,\n",
    "        PoseLandmark.RIGHT_ANKLE,\n",
    "        PoseLandmark.LEFT_HEEL,\n",
    "        PoseLandmark.RIGHT_HEEL,\n",
    "        PoseLandmark.LEFT_FOOT_INDEX,\n",
    "        PoseLandmark.RIGHT_FOOT_INDEX\n",
    "    ]\n",
    "\n",
    "    for landmark in excluded_landmarks:\n",
    "        custom_pose_connections = [connection_tuple for connection_tuple in custom_pose_connections if landmark.value not in connection_tuple]\n",
    "\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, connections=custom_pose_connections)\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw landmarks with style (different color)\n",
    "def draw_styled_handmarks(image, results):\n",
    "    # mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION , \n",
    "    #                          mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "    #                          mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "    #                          ) \n",
    "   \n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2),\n",
    "                             ) \n",
    "      \n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "     \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\krisn\\OneDrive\\Desktop\\Learning\\machine-learning-study\\testing-space\\testing_mediapipe.ipynb Cell 7\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krisn/OneDrive/Desktop/Learning/machine-learning-study/testing-space/testing_mediapipe.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwhile\u001b[39;00m cap\u001b[39m.\u001b[39misOpened():\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krisn/OneDrive/Desktop/Learning/machine-learning-study/testing-space/testing_mediapipe.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     ret, frame \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39mread()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/krisn/OneDrive/Desktop/Learning/machine-learning-study/testing-space/testing_mediapipe.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     image, results \u001b[39m=\u001b[39m media_pipe_detection(frame, holistic)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krisn/OneDrive/Desktop/Learning/machine-learning-study/testing-space/testing_mediapipe.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     draw_land_marks(image, results)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krisn/OneDrive/Desktop/Learning/machine-learning-study/testing-space/testing_mediapipe.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# FOR BLACK BACKGROUND\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/krisn/OneDrive/Desktop/Learning/machine-learning-study/testing-space/testing_mediapipe.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# image, results = media_pipe_detection(frame, holistic)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/krisn/OneDrive/Desktop/Learning/machine-learning-study/testing-space/testing_mediapipe.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# black_bg = np.zeros((frame.shape[0], frame.shape[1], frame.shape[2]))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/krisn/OneDrive/Desktop/Learning/machine-learning-study/testing-space/testing_mediapipe.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m# draw_land_marks(black_bg, results)\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\krisn\\OneDrive\\Desktop\\Learning\\machine-learning-study\\testing-space\\testing_mediapipe.ipynb Cell 7\u001b[0m line \u001b[0;36mmedia_pipe_detection\u001b[1;34m(image, model)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krisn/OneDrive/Desktop/Learning/machine-learning-study/testing-space/testing_mediapipe.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmedia_pipe_detection\u001b[39m(image, model):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/krisn/OneDrive/Desktop/Learning/machine-learning-study/testing-space/testing_mediapipe.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     image \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39;49mcvtColor(image, cv\u001b[39m.\u001b[39;49mCOLOR_BGR2RGB) \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krisn/OneDrive/Desktop/Learning/machine-learning-study/testing-space/testing_mediapipe.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     image\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mwriteable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krisn/OneDrive/Desktop/Learning/machine-learning-study/testing-space/testing_mediapipe.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mprocess(image)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "cap = cv.VideoCapture(0) \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        image, results = media_pipe_detection(frame, holistic)\n",
    "        draw_land_marks(image, results)\n",
    "\n",
    "        # FOR BLACK BACKGROUND\n",
    "        # image, results = media_pipe_detection(frame, holistic)\n",
    "        # black_bg = np.zeros((frame.shape[0], frame.shape[1], frame.shape[2]))\n",
    "        # draw_land_marks(black_bg, results)\n",
    "        \n",
    "        cv.imshow('Media Pipe Test', image)\n",
    "        \n",
    "        if(cv.waitKey(10) & 0xFF == ord(' ')):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv.cvtColor(image, cv.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    # face = np.array([[res.x, res.y] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*2)\n",
    "\n",
    "    # pose = np.array([[res.x, res.y] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*2)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        selected_pose_landmarks = results.pose_landmarks.landmark[11:23]\n",
    "        pose = np.array([[res.x, res.y] for res in selected_pose_landmarks]).flatten()\n",
    "    else:\n",
    "        pose = np.zeros(22*2)\n",
    "\n",
    "        \n",
    "    left_hand = np.array([[res.x, res.y] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*2)\n",
    "    right_hand = np.array([[res.x, res.y] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*2)\n",
    "   \n",
    "    # return np.concatenate([pose, face, left_hand, right_hand])\n",
    "    return np.concatenate([pose, left_hand, right_hand])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Extract Keypoint Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    # face = np.array([[res.x, res.y] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*2)\n",
    "\n",
    "    # pose = np.array([[res.x, res.y] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*2)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        selected_pose_landmarks = results.pose_landmarks.landmark[11:23]\n",
    "        pose = np.array([[res.x, res.y] for res in selected_pose_landmarks]).flatten()\n",
    "    else:\n",
    "        pose = np.zeros(22*2)\n",
    "\n",
    "        \n",
    "    left_hand = np.array([[res.x, res.y] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*2)\n",
    "    right_hand = np.array([[res.x, res.y] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*2)\n",
    "   \n",
    "    # return np.concatenate([pose, face, left_hand, right_hand])\n",
    "    return np.concatenate([pose, left_hand, right_hand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coordinate(results):\n",
    "    # if results.face_landmarks:\n",
    "    #     for res in results.face_landmarks.landmark:\n",
    "    #         x = res.x\n",
    "    #         y = res.y\n",
    "    #         visibility = res.visibility\n",
    "    #         print(f\"FACE LANDMARK x: {x}, y: {y}\\n\")    \n",
    "        \n",
    "    # NORMAL POSE LANDMARK\n",
    "    # if results.pose_landmarks:\n",
    "    #     for res in results.pose_landmarks.landmark:\n",
    "    #         x = res.x\n",
    "    #         y = res.y\n",
    "    #         print(f\"POSE LANDMARK x: {x}, y: {y}\\n\")\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        selected_pose_landmarks = results.pose_landmarks.landmark[11:23]\n",
    "        for res in selected_pose_landmarks:\n",
    "            x = res.x\n",
    "            y = res.y\n",
    "            print(f\"POSE LANDMARK x: {x}, y: {y}\\n\")\n",
    "        \n",
    "    if results.right_hand_landmarks:\n",
    "        for res in results.right_hand_landmarks.landmark:\n",
    "            x = res.x\n",
    "            y = res.y\n",
    "            print(f\"RIGHT HAND LANDMARK x: {x}, y: {y}\\n\")\n",
    "    if results.left_hand_landmarks:\n",
    "        for res in results.left_hand_landmarks.landmark:\n",
    "            x = res.x\n",
    "            y = res.y\n",
    "            print(f\"LEFT HAND LANDMARK x: {x}, y: {y}\\n\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extract_coordinate(results))\n",
    "print(extract_keypoints(results))\n",
    "print(len(extract_keypoints(results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
