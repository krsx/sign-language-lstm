{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"tensorflow==2.13.0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from mediapipe.python.solutions.pose import PoseLandmark\n",
    "from mediapipe.python.solutions.drawing_utils import DrawingSpec\n",
    "import math\n",
    "from mediapipe.framework.formats import landmark_pb2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Access using Using MediaPipe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define mediapipe holistic and drawing utils\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect using mediapipe model\n",
    "def media_pipe_detection(image, model):\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB) \n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv.cvtColor(image, cv.COLOR_RGB2BGR) \n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def center_landmarks(landmarks, shoulder_midpoint):\n",
    "#     centered_landmarks = landmark_pb2.NormalizedLandmarkList()\n",
    "#     for lm in landmarks.landmark:\n",
    "#         centered_lm = centered_landmarks.landmark.add()\n",
    "#         centered_lm.x = lm.x - shoulder_midpoint[0]\n",
    "#         centered_lm.y = lm.y - shoulder_midpoint[1]\n",
    "#         centered_lm.z = lm.z  # Retaining the original z-coordinate\n",
    "#     return centered_landmarks\n",
    "\n",
    "# def draw_land_marks(image, results, mp_drawing, mp_holistic, mp_pose):\n",
    "#     if results.pose_landmarks:\n",
    "#         # Calculate the midpoint of the shoulders\n",
    "#         left_shoulder = np.array([results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "#                                   results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y])\n",
    "#         right_shoulder = np.array([results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "#                                    results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y])\n",
    "#         shoulder_midpoint = (left_shoulder + right_shoulder) / 2\n",
    "\n",
    "#         # Center landmarks\n",
    "#         centered_pose_landmarks = center_landmarks(results.pose_landmarks, shoulder_midpoint)\n",
    "#         centered_left_hand = center_landmarks(results.left_hand_landmarks, shoulder_midpoint) if results.left_hand_landmarks else None\n",
    "#         centered_right_hand = center_landmarks(results.right_hand_landmarks, shoulder_midpoint) if results.right_hand_landmarks else None\n",
    "\n",
    "#         # Drawing the centered landmarks\n",
    "#         mp_drawing.draw_landmarks(image, centered_pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "#         if centered_left_hand:\n",
    "#             mp_drawing.draw_landmarks(image, centered_left_hand, mp_holistic.HAND_CONNECTIONS)\n",
    "#         if centered_right_hand:\n",
    "#             mp_drawing.draw_landmarks(image, centered_right_hand, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "def draw_land_marks(image, results):\n",
    "    # mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION)\n",
    "    \n",
    "    # mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "\n",
    "    custom_pose_connections = list(mp_pose.POSE_CONNECTIONS)\n",
    "    \n",
    "    excluded_landmarks = [\n",
    "        PoseLandmark.NOSE,\n",
    "        PoseLandmark.LEFT_EYE_INNER,\n",
    "        PoseLandmark.LEFT_EYE,\n",
    "        PoseLandmark.LEFT_EYE_OUTER,\n",
    "        PoseLandmark.RIGHT_EYE_INNER,\n",
    "        PoseLandmark.RIGHT_EYE,\n",
    "        PoseLandmark.RIGHT_EYE_OUTER,\n",
    "        PoseLandmark.LEFT_EAR,\n",
    "        PoseLandmark.RIGHT_EAR,\n",
    "        PoseLandmark.MOUTH_LEFT,\n",
    "        PoseLandmark.MOUTH_RIGHT,\n",
    "        PoseLandmark.LEFT_HIP,\n",
    "        PoseLandmark.RIGHT_HIP,\n",
    "        PoseLandmark.LEFT_KNEE,\n",
    "        PoseLandmark.RIGHT_KNEE,\n",
    "        PoseLandmark.LEFT_ANKLE,\n",
    "        PoseLandmark.RIGHT_ANKLE,\n",
    "        PoseLandmark.LEFT_HEEL,\n",
    "        PoseLandmark.RIGHT_HEEL,\n",
    "        PoseLandmark.LEFT_FOOT_INDEX,\n",
    "        PoseLandmark.RIGHT_FOOT_INDEX\n",
    "    ]\n",
    "\n",
    "    for landmark in excluded_landmarks:\n",
    "        custom_pose_connections = [connection_tuple for connection_tuple in custom_pose_connections if landmark.value not in connection_tuple]\n",
    "\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, connections=custom_pose_connections)\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw landmarks with style (different color)\n",
    "def draw_styled_handmarks(image, results):\n",
    "    # mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION , \n",
    "    #                          mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "    #                          mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "    #                          ) \n",
    "   \n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2),\n",
    "                             ) \n",
    "      \n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "     \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints_normalize(results):\n",
    "    # face = np.array([[res.x, res.y] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*2)\n",
    "\n",
    "    # pose = np.array([[res.x, res.y] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*2)\n",
    "    shoulder_width = 1\n",
    "    midpoint_shoulder_x = 1\n",
    "    midpoint_shoulder_y = 1\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        selected_pose_landmarks = results.pose_landmarks.landmark[11:23]\n",
    "        \n",
    "        midpoint_shoulder_x = (selected_pose_landmarks[0].x + selected_pose_landmarks[1].x) / 2\n",
    "        midpoint_shoulder_y = (selected_pose_landmarks[0].y + selected_pose_landmarks[1].y) / 2\n",
    "\n",
    "        shoulder_width = math.sqrt(pow((selected_pose_landmarks[1].x - selected_pose_landmarks[0].x) , 2) + pow((selected_pose_landmarks[1].y - selected_pose_landmarks[0].y) ,2))\n",
    "\n",
    "        pose = np.array([[(res.x - midpoint_shoulder_x) / shoulder_width, (res.y - midpoint_shoulder_y) / shoulder_width] for res in selected_pose_landmarks]).flatten()\n",
    "    else:\n",
    "        pose = np.zeros(22*2)\n",
    "\n",
    "        \n",
    "    left_hand = np.array([[(res.x - midpoint_shoulder_x) / shoulder_width, (res.y - midpoint_shoulder_y) / shoulder_width] for res in  results.left_hand_landmarks]).flatten() if results.left_hand_landmarks else np.zeros(21*2)\n",
    "    right_hand = np.array([[(res.x - midpoint_shoulder_x) / shoulder_width, (res.y - midpoint_shoulder_y) / shoulder_width] for res in results.right_hand_landmarks]).flatten() if results.right_hand_landmarks else np.zeros(21*2)\n",
    "   \n",
    "    # return np.concatenate([pose, face, left_hand, right_hand])\n",
    "    return np.concatenate([pose, left_hand, right_hand])\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    # face = np.array([[res.x, res.y] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*2)\n",
    "\n",
    "    # pose = np.array([[res.x, res.y] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*2)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        selected_pose_landmarks = results.pose_landmarks.landmark[11:23]\n",
    "        pose = np.array([[res.x, res.y] for res in selected_pose_landmarks]).flatten()\n",
    "    else:\n",
    "        pose = np.zeros(22*2)\n",
    "\n",
    "        \n",
    "    left_hand = np.array([[res.x, res.y] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*2)\n",
    "    right_hand = np.array([[res.x, res.y] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*2)\n",
    "   \n",
    "    # return np.concatenate([pose, face, left_hand, right_hand])\n",
    "    return np.concatenate([pose, left_hand, right_hand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISPLAY USING WEBCAM\n",
    "cap = cv.VideoCapture(0) \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        image, results = media_pipe_detection(frame, holistic)\n",
    "        draw_land_marks(image, results)\n",
    "        # draw_land_marks(image, results, mp_drawing, mp_holistic, mp_pose)\n",
    "\n",
    "        # FOR BLACK BACKGROUND\n",
    "        # image, results = media_pipe_detection(frame, holistic)\n",
    "        # black_bg = np.zeros((frame.shape[0], frame.shape[1], frame.shape[2]))\n",
    "        # draw_land_marks(black_bg, results)\n",
    "        \n",
    "        cv.imshow('Media Pipe Test', image)\n",
    "        \n",
    "        if(cv.waitKey(10) & 0xFF == ord(' ')):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv.cvtColor(image, cv.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    # face = np.array([[res.x, res.y] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*2)\n",
    "\n",
    "    # pose = np.array([[res.x, res.y] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*2)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        selected_pose_landmarks = results.pose_landmarks.landmark[11:23]\n",
    "        pose = np.array([[res.x, res.y] for res in selected_pose_landmarks]).flatten()\n",
    "    else:\n",
    "        pose = np.zeros(22*2)\n",
    "\n",
    "        \n",
    "    left_hand = np.array([[res.x, res.y] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*2)\n",
    "    right_hand = np.array([[res.x, res.y] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*2)\n",
    "   \n",
    "    # return np.concatenate([pose, face, left_hand, right_hand])\n",
    "    return np.concatenate([pose, left_hand, right_hand])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Extract Keypoint Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    # face = np.array([[res.x, res.y] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*2)\n",
    "\n",
    "    # pose = np.array([[res.x, res.y] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*2)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        selected_pose_landmarks = results.pose_landmarks.landmark[11:23]\n",
    "        pose = np.array([[res.x, res.y] for res in selected_pose_landmarks]).flatten()\n",
    "    else:\n",
    "        pose = np.zeros(22*2)\n",
    "\n",
    "        \n",
    "    left_hand = np.array([[res.x, res.y] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*2)\n",
    "    right_hand = np.array([[res.x, res.y] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*2)\n",
    "   \n",
    "    # return np.concatenate([pose, face, left_hand, right_hand])\n",
    "    return np.concatenate([pose, left_hand, right_hand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coordinate(results):\n",
    "    # if results.face_landmarks:\n",
    "    #     for res in results.face_landmarks.landmark:\n",
    "    #         x = res.x\n",
    "    #         y = res.y\n",
    "    #         visibility = res.visibility\n",
    "    #         print(f\"FACE LANDMARK x: {x}, y: {y}\\n\")    \n",
    "        \n",
    "    # NORMAL POSE LANDMARK\n",
    "    # if results.pose_landmarks:\n",
    "    #     for res in results.pose_landmarks.landmark:\n",
    "    #         x = res.x\n",
    "    #         y = res.y\n",
    "    #         print(f\"POSE LANDMARK x: {x}, y: {y}\\n\")\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        selected_pose_landmarks = results.pose_landmarks.landmark[11:23]\n",
    "        for res in selected_pose_landmarks:\n",
    "            x = res.x\n",
    "            y = res.y\n",
    "            # print(f\"POSE LANDMARK x: {x}, y: {y}\\n\")\n",
    "        \n",
    "    if results.right_hand_landmarks:\n",
    "        for res in results.right_hand_landmarks.landmark:\n",
    "            x = res.x\n",
    "            y = res.y\n",
    "            # print(f\"RIGHT HAND LANDMARK x: {x}, y: {y}\\n\")\n",
    "    if results.left_hand_landmarks:\n",
    "        for res in results.left_hand_landmarks.landmark:\n",
    "            x = res.x\n",
    "            y = res.y\n",
    "            # print(f\"LEFT HAND LANDMARK x: {x}, y: {y}\\n\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extract_coordinate(results))\n",
    "print(extract_keypoints(results))\n",
    "print(len(extract_keypoints(results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
